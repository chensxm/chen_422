(1) [ 单选 ] ID:16395
back-propagation through time算法是常用的训练RNN的方法，其实本质还是（ ） 
A) 前向算法
B) BP算法
C) 回归算法
D) LSTM算法
回答： 
答案： B


(2) [ 单选 ] ID:16393
RNN具有（ ）展开的特点，这是由其输入决定的 
A) 时间
B) 空间
C) BP算法
D) LSTM
回答： 
答案： A


(3) [ 单选 ] ID:16388
在有监督学习中，标签起的一个作用是 
A) 监督
B) 度量
C) 观察
D) 学习
回答： 
答案： A


(4) [ 单选 ] ID:16396
RNN的关键点之一就是他们可以用来连接( )的信息到当前的任务上 
A) 先前
B) 之后
C) 丢失
D) LSTM
回答： 
答案： A


(5) [ 单选 ] ID:16394
基础的神经网络只在层与层之间建立了权连接，RNN最大的不同之处就是在层之间的神经元之间也建立的( ) 
A) 权连接
B) 层连接
C) 前馈连接
D) 反馈连接
回答： 
答案： A


(6) [ 单选 ] ID:16656
以下关于循环神经网络的说法中，哪个是正确的？ 
A) 循环神经网络可以和卷积神经网络混合使用
B) 循环神经网络的性能高于卷积神经网络
C) 循环神经网络可以代替卷积神经网络
D) 循环神经网络中没有BP算法
回答： 
答案： A


(7) [ 单选 ] ID:16646
tf.equal(0, False)的结果是 
A) 1
B) 0
C) True
D) False
回答： 
答案： C


(8) [ 单选 ] ID:16392
全连接网络对一个样本做一次forward，RNN对一个样本做（ ）次forward 
A) 1
B) 多
C) 2
D) 3
回答： 
答案： B


(9) [ 单选 ] ID:16391
距离空间有多种多样，他们的目的是 
A) 度量后比较
B) 求相关性
C) 求信息熵
D) 构成线性空间
回答： 
答案： A


(10) [ 单选 ] ID:16600
循环神经网络的英文全称是？ 
A) Recurrent Neural Network
B) Repeat Neural Network
C) Round Neural Network
D) Recurse Neural Network
回答： 
答案： A


(11) [ 单选 ] ID:16653
随时间反向传播的缩写是哪个？ 
A) BPTT
B) BP
C) BPT
D) BPTM
回答： 
答案： A


(12) [ 单选 ] ID:16398
以下的序列数据中，属于一对多（一个输入，多个输出）的关系是哪个？ 
A) 音乐生成
B) 情感分类
C) 机器翻译
D) DNA序列分析
回答： 
答案： A


(13) [ 单选 ] ID:16399
编码器-解码器模式属于以下哪种模式？ 
A) 一对一
B) 一对多
C) 多对一
D) 多对多
回答： 
答案： D


(14) [ 单选 ] ID:16649
a = tf.Variable(8.1)
sess.run(tf.assign_add(a, 1))
a的值是： 
A) 8.1
B) 8.2
C) 9.1
D) 7.1
回答： 
答案： C


(15) [ 单选 ] ID:16389
卷积神经网络中，全连接层中，需要修改权重，修改的依据是： 
A) 梯度反向传播
B) 梯度正向传播
C) 与梯度无关
D) 与损失函数无关
回答： 
答案： A


(16) [ 单选 ] ID:16386
在监督学习中，标签起监督作用，监督的目的是指导 
A) 修正权重参数
B) 求出信息熵
C) 特征提取
D) 预处理数据
回答： 
答案： A


(17) [ 单选 ] ID:16652
深度神经网络的缩写是？ 
A) CNN
B) RNN
C) SNN
D) DNN
回答： 
答案： D


(18) [ 单选 ] ID:16390
在贝努力实验是（）的理论基础 
A) 交叉熵损失函数
B) 最小二乘损失函数
C) 与二项式分布有关
D) 与信息量有关
回答： 
答案： A


(19) [ 单选 ] ID:16387
所谓权重参数，是指： 
A) 输入数据的变换矩阵
B) 输出数据的变换矩阵
C) 是激活函数
D) 是将数据影射到概率空间
回答： 
答案： A


(20) [ 单选 ] ID:16397
哪些序列数据属于多对一（多个输入，一个输出）的关系 
A) 语音识别
B) 情感分类
C) 机器翻译
D) DNA序列分析
回答： 
答案： B


(21) [ 多选 ] ID:16400
下面哪些序列数据属于多对多（多个输入，多个输出）的关系 
A) 音乐生成
B) 情感分类
C) 编码器-解码器
D) 机器翻译
回答： 
答案： CD


(22) [ 多选 ] ID:16407
假定一个全连接网络有三个权重矩阵维度为W1[a,b]，W2[c,d],W3[e,f]，该网络 
A) 输入维度为[M，a]
B) 输出维度[M，f]
C) 输入数据维度为[a，b]
D) 输出数据维度为[e，f]
回答： 
答案： AB


(23) [ 多选 ] ID:16402
对于矩阵A可以求逆，那么A必须 
A) 是方阵
B) 行列式不为零
C) 任意矩阵
D) 行列式为1
回答： 
答案： AB


(24) [ 多选 ] ID:16404
线性变换中，若A是方阵，用A对线性空间的向量t进行变换。其结果为T 
A) 变换前后向量模有变化
B) t角度变化到T
C) T也是向量
D) T和t维度相同
回答： 
答案： ABCD


(25) [ 多选 ] ID:16410
哪些属于序列数据 
A) 语音识别
B) 情感分类
C) 机器翻译
D) DNA序列分析
回答： 
答案： ABCD


(26) [ 多选 ] ID:16406
在卷积神经网络中，随机生成的卷积核后： 
A) 个别一些卷积核对特征提取几乎无贡献
B) 每个卷积核对特定特征进行提取
C) 有信号共振的原理
D) 特征最后形成编码，送入全连接网络
回答： 
答案： ABCD


(27) [ 多选 ] ID:16405
CNN的网络训练后，形成模块model，其中数据包括 
A) 所有卷积核
B) 所有的pooling
C) 连接层权重
D) relu
回答： 
答案： ABCD


(28) [ 多选 ] ID:16401
哪些框架支持运行循环神经网络？ 
A) TensorFlow
B) Keras
C) Caffe
D) PyTorch
回答： 
答案： ABCD


(29) [ 多选 ] ID:16409
BPTT算法是针对循环层的训练算法，它的基本原理和BP算法是一样的，也包含同样的几个步骤： 
A) 前向计算每个神经元的输出值
B) 反向计算每个神经元的误差项值，它是误差函数E对神经元j的加权输入的偏导数
C) 计算每个权重的梯度
D) 最后再用随机梯度下降算法更新权重
回答： 
答案： ABCD


(30) [ 多选 ] ID:16408
关于正则化的正确说法有： 
A) 要求在损失函数加正则化项
B) 是强制将w更新进行截止
C) 会减少过拟合
D) 会增加过拟合
回答： 
答案： ABC


(31) [ 判断 ] ID:16415
在步长迭代运算中，连续函数与间断函数比较，好处在于，能够不间断运算。 
回答： 
答案： 是


(32) [ 判断 ] ID:16416
在程序中如果涉及区间条件判断，一定在全部条件进行验证。 
回答： 
答案： 是


(33) [ 判断 ] ID:16411
循环神经网络的权重系数是共享的，即在一次迭代中，循环节点使用相同的权重系数处理所有的时间步。 
回答： 
答案： 是


(34) [ 判断 ] ID:16414
对于非规范的两个序列，比较相似度，可以用内积的原理。 
回答： 
答案： 是


(35) [ 判断 ] ID:16412
对于非规范的两个序列，比较相似度，可以用信息熵原理。 
回答： 
答案： 是


(36) [ 判断 ] ID:16413
损失函数反映的是，标签集合与训练集合变换后结果的总体差别。 
回答： 
答案： 是


(37) [ 判断 ] ID:16418
所谓损失函数，只有在训练的时候才参与运算，在训练以后，测试或应用中无需损失函数。 
回答： 
答案： 是


(38) [ 判断 ] ID:16420
Recurrent Neural Network。神经网络是一种节点定向连接成环的人工神经网络 
回答： 
答案： 是


(39) [ 判断 ] ID:16419
RNN的结构与全连接网络基本不一致 
回答： 
答案： 否


(40) [ 判断 ] ID:16417
用偏执参与运算，就是为了能够平移分类超平面。 
回答： 
答案： 是


(41) [ 判断 ] ID:16421
Recurrent Neural Network，RNN这种网络的本质特征是在处理单元之间既有内部的反馈连接又有前馈连接 
回答： 
答案： 是
