(1) [ 单选 ] ID:15906
tf.cast(x, tf.int32)将x类型转化成 
A) 返回整数值
B) 返回布尔值
C) 返回浮点值
D) 返回字符
回答： 
答案： A


(2) [ 单选 ] ID:16216
卷积定理指出，函数卷积的傅里叶变换是函数傅里叶变换的（ ）。即，一个域中的卷积相当于另一个域中的（ ），例如时域中的卷积就对应于频域中的乘积。 
A) 乘积，乘积
B) 乘积，范数
C) 范数，乘积
D) 范数，距离
回答： 
答案： A


(3) [ 单选 ] ID:16213
activation function Rectified Linear Unit即激活函数ReLU，它的作用是( ) 
A) 引用了无效的单元格地址
B) 过滤无效神经元
C) 不是激发函数
D) 将正数保留，将负数置0
回答： 
答案： D


(4) [ 单选 ] ID:16214
卷积神经网络中每层卷积层（Convolutional layer）由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法最佳化得到，其作用是（） 
A) 增强图像
B) 简化图像
C) 特征提取
D) 图像处理
回答： 
答案： C


(5) [ 单选 ] ID:16210
神经网络需要激活函数，其原因是可实现 
A) 解决线性可分性
B) 非线性分类
C) 归一化
D) 正则化
回答： 
答案： B


(6) [ 单选 ] ID:16207
tf.nn.conv2d()，其中遇到的图像张量，格式是 
A) [batch, in_height, in_width, in_channels]
B) [Size, in_height, in_width, in_channels]
C) [batch, in_width, in_height， in_channels]
D) [batch, in_channels，in_height, in_width ]
回答： 
答案： A


(7) [ 单选 ] ID:16542
conv2d(x_image, W_conv1) + b_conv）中b_conv1是 
A) 对图像池化
B) 偏置项
C) 激活函数
D) 平均
回答： 
答案： B


(8) [ 单选 ] ID:16215
一类包含卷积或相关计算且具有深度结构的前馈神经网络（Feedforward Neural Networks）也称为（） 
A) 机器学习
B) 数据挖掘
C) CNN卷积神经网络
D) MATLAB
回答： 
答案： C


(9) [ 单选 ] ID:16205
tf.nn.conv2d(a, b, c, d )，其中b是 
A) 被卷积数据
B) 卷积核
C) 步长
D) 填充
回答： 
答案： B


(10) [ 单选 ] ID:16212
在深度学习中，如果输入图像有2个，经过10个卷积核卷积后，输出图像有 
A) 2
B) 5
C) 10
D) 不确定
回答： 
答案： C


(11) [ 单选 ] ID:16208
定义一个卷积核filter，它的张量定义为filter=tf.Variable(tf.random_normal([20,10,3,16]))则卷积核的高度是： 
A) 10
B) 20
C) 16
D) 3
回答： 
答案： B


(12) [ 单选 ] ID:16546
在h_fc1 = tf.nn.relu(tf.matmul(h_flat, W_fc1) + b_fc1)操作,b_fc1是 
A) 对图像池化
B) 偏置项
C) 激活函数
D) 平均
回答： 
答案： B


(13) [ 单选 ] ID:16206
一个32X32大小的图像，通过步长为2，尺寸为2X2的池化运算后，尺寸变为 
A) 14X14
B) 2X2
C) 28X28
D) 16X16
回答： 
答案： D


(14) [ 单选 ] ID:16217
常用的激活函数RELU，其常用调用语句为那一个（） 
A) h_conv1 = tf.nn.relu( conv_ret1 )
B) h_conv1 = tf.nn.dropout( conv_ret1 )
C) h_conv1 = tf.nn.lrn( conv_ret1 )
D) h_conv1 = tf.nn.l2_loss( conv_ret1 )
回答： 
答案： A


(15) [ 单选 ] ID:16025
数学建模工作，首先要对目标事物进行（），然后再进行下一步工作。 
A) 度量化
B) 抽象化
C) 具体化
D) 理想化
回答： 
答案： A


(16) [ 单选 ] ID:16209
在函数的上升速度来看，最慢的是 
A) 线性函数
B) 指数函数
C) 幂函数
D) 对数函数
回答： 
答案： D


(17) [ 单选 ] ID:16547
定义步长张量strides=[1, 3, 3, 1]能纵向移动 
A) 1像素
B) 2像素
C) 3像素
D) 4像素
回答： 
答案： C


(18) [ 单选 ] ID:16218
max pooling是CNN当中的最大值池化操作，其实用法和卷积很类似，（ ）仍然是[batch, height, width, channels]这种形式 
A) value
B) shape
C) strides
D) padding
回答： 
答案： B


(19) [ 单选 ] ID:16204
tf.nn.conv2d(a, b, c, d )，其中被卷积数据是 
A) b
B) a
C) c
D) d
回答： 
答案： B


(20) [ 单选 ] ID:16543
池化核ksize=[1, 4, 4, 1]将图像 
A) 缩小到1/2
B) 缩小到1/16
C) 扩大两倍
D) 扩大四倍
回答： 
答案： B


(21) [ 多选 ] ID:16221
在tensorflow平台中，能实现卷积运算的函数是： 
A) tf.nn.conv2d
B) tf.nn.depthwise_conv2d
C) tf.nn.convolution
D) tf.random_normal
回答： 
答案： ABC


(22) [ 多选 ] ID:16220
关于LeNet深度神经网络的构成，它的组成描述是 
A) 卷积层
B) 激活函数
C) 池化层
D) 全连接层
回答： 
答案： ABCD


(23) [ 多选 ] ID:16223
关于Padding的说法中：正确的是 
A) 以0填充
B) 填充厚度是卷积核一半
C) 步长为1
D) 图像尺寸变小
回答： 
答案： AB


(24) [ 多选 ] ID:16224
通常深度学习网络的卷积层部分的组成有 
A) 卷积层
B) RELU
C) POOLING层
D) pedding
回答： 
答案： ABC


(25) [ 多选 ] ID:16228
Tensorflow实现cnn模型的训练与使用开发过程的步骤通常包括（） 
A) 准备样本集合
B) 前向传递，求出loss
C) 求出反向的梯度
D) 按照梯度的反向传播，更新参数
回答： 
答案： ABCD


(26) [ 多选 ] ID:16222
关于卷积核是个张量，本身的参数，它包括有： 
A) 高度
B) 宽度
C) 输入通道
D) 输出通道
回答： 
答案： ABCD


(27) [ 多选 ] ID:16226
浅层神经网络与深度神经网络比较，其区别之处是? 
A) 浅层结构算法：其局限性在于有限样本和计算单元情况下对复杂函数的表示能力有限，针对复杂分类问题其泛化能力受到一定制约
B) 深度学习可通过学习一种深层非线性网络结构，实现复杂函数逼近，表征输入数据分布式表示，并展现了强大的从少数样本集中学习数据集本质特征的能力。
C) 深度学习多层的好处是可以用较少的参数表示复杂的函数
D) 深度学习的实质，是通过构建具有很多隐层的机器学习模型和海量的训练数据，来学习更有用的特征，从而最终提升分类或预测的准确性。
回答： 
答案： ABCD


(28) [ 多选 ] ID:16219
深度学习训练中，包含以下步骤； 
A) 准备样本集合
B) 前向传递，求出loss
C) 求出反向的梯度dY
D) 按照梯度dY，确定的更新参数，更新X，继续循环
回答： 
答案： ABCD


(29) [ 多选 ] ID:16227
由深度神经网络构成的网络结构中，其构成通常会包括那些层? 
A) 输入层
B) 卷积层（激活函数）
C) 池化层
D) 全连接层
回答： 
答案： ABCD


(30) [ 多选 ] ID:16225
在深度学习中，从结构上说，卷积神经网络由（）和（）层构成 
A) 卷积层
B) 全连接层
C) 图像滤波层
D) 边缘提取层
回答： 
答案： AB


(31) [ 判断 ] ID:16571
卷积神经网络更靠后的一些层可检测完整的物体、复杂的特征。 
回答： 
答案： 是


(32) [ 判断 ] ID:16569
tf.nn.conv2d中的参数padding="SAME"，如果卷积核3*3，会自动填充1圈0。 
回答： 
答案： 是


(33) [ 判断 ] ID:16572
卷积神经网络的tensorflow框架中，tf.nn.avg_pool()可实现平均池化操作。 
回答： 
答案： 是


(34) [ 判断 ] ID:16231
在卷积神经网络中，可以利用多个不同的卷积核进行卷积操作 
回答： 
答案： 是


(35) [ 判断 ] ID:16229
relu函数就是正数不变，负数取零的激活函数 
回答： 
答案： 是


(36) [ 判断 ] ID:16233
两个信号序列形状相似，其相关系数也大。 
回答： 
答案： 是


(37) [ 判断 ] ID:16570
卷积神经网络的前几层检查提取例如边缘这样的简单特征 
回答： 
答案： 是


(38) [ 判断 ] ID:16235
在卷积神经网络中实施填充是一件十分重要的事情，如果没有填充，边缘区域的像素值基本不会受到卷积层的影响 
回答： 
答案： 是


(39) [ 判断 ] ID:16232
自然界任何一个物理系统都存在固定振动频率，当外界有相同频率振动，就能使该物体产生共振。 
回答： 
答案： 是


(40) [ 判断 ] ID:16234
导数和偏导没有本质区别,都是当自变量的变化量趋于0时，函数值的变化量与自变量变化量比值的极限 
回答： 
答案： 是
