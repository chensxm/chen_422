(1) [ 单选 ] ID:16052
TensorFlow？ 是一个开放源代码软件库，用于进行高性能数值计算。借助其灵活的架构，用户可以轻松地将计算工作部署到多种平台（）和设备（桌面设备、服务器集群、移动设备、边缘设备等） 
A) CPU、GPU、TPU
B) CPU、GPU
C) CPU
D) TPU
回答： 
答案： A


(2) [ 单选 ] ID:16024
函数tanh值域范围是（ ） 
A) +1 和-1
B) +0 和-1
C) +1 和0
D) +2 和-2
回答： 
答案： A


(3) [ 单选 ] ID:16041
双曲正切函数指的是那一个函数? 
A) Sigmoid函数
B) tanh函数
C) ReLU
D) leaky ReLU
回答： 
答案： B


(4) [ 单选 ] ID:16049
双曲正切函数即（ ），取值范围为[-1,1] 
A) RelU函数
B) sigmoid函数
C) tanh函数
D) sin函数
回答： 
答案： C


(5) [ 单选 ] ID:16048
TensorFlow、Keras框架为机器学习ML和（ ）提供了灵活的数值计算核心 
A) ML
B) 算法重构
C) NPL
D) 深度学习
回答： 
答案： D


(6) [ 单选 ] ID:16053
tf.ones_like(tensor)该操作返回一个具有和给定tensor相同形状（shape）和相同数据类型（dtype） 
A) dtype
B) tensor
C) shape
D) int
回答： 
答案： B


(7) [ 单选 ] ID:16051
从输入层到（ ），再到输出层。 逐层计算每一个节点对其下一层节点的影响，这就是前向传播算法 
A) 输出层
B) 隐藏层
C) 输入层
D) 激活函数层
回答： 
答案： B


(8) [ 单选 ] ID:16040
在深度学习中，前向算法就是有了联结权重w和( )H(x)之后，就可以由前往后面层计算 
A) 激活函数
B) 正弦函数
C) 余弦函数
D) Sigmoid函数
回答： 
答案： A


(9) [ 单选 ] ID:16044
神经网络中常用的( )Sigmoid函数 ，会把量映射到0,1之间 
A) 非激活
B) RELU
C) 极值
D) 阈值
回答： 
答案： D


(10) [ 单选 ] ID:16028
卷积层的作用是 
A) 增强图像
B) 简化图像
C) 特征提取
D) 图像处理
回答： 
答案： C


(11) [ 单选 ] ID:16042
修正线性单元函数是指? 
A) Sigmoid函数
B) tanh函数
C) ReLU
D) leaky ReLU
回答： 
答案： C


(12) [ 单选 ] ID:16031
有多个卷积核的原因是： 
A) 同时提取多个图像的特征
B) 提取某些图像多个特征
C) 图像有多个通道
D) 与多特征无关
回答： 
答案： B


(13) [ 单选 ] ID:16032
图像特征经过几个卷积后，特征信号： 
A) 减弱
B) 不变
C) 增强
D) 都有可能
回答： 
答案： D


(14) [ 单选 ] ID:16039
如果从python一侧，想得到tf的节点S对应的值，需要下列： 
A) A=tf.run(S)
B) A=S.value
C) A=S.eval()
D) tf.assign(A,S)
回答： 
答案： A


(15) [ 单选 ] ID:16043
带泄露的ReLU函数是指? 
A) Sigmoid函数
B) tanh函数
C) ReLU
D) leaky ReLU
回答： 
答案： D


(16) [ 单选 ] ID:16045
在前向传播反向传播过程中，例如求导结果为f(z)' = f(z)(1 ? f(z))那么这个激活函数最有可能会是下面选项中的那一个?（） 
A) RelU函数
B) tanh
C) cosh
D) sigmoid
回答： 
答案： D


(17) [ 单选 ] ID:16034
图像处理时，给定输入图像，在输出图像中每一个像素是输入图像中一个小区域中像素的加权平均，其中权值由一个函数定义，这个函数称为（） 
A) 被卷积数据
B) 卷积核
C) 步长
D) 填充
回答： 
答案： B


(18) [ 单选 ] ID:16030
输入图像有2个，经过10个卷积核卷积后，输出图像有（）个 
A) 2
B) 5
C) 10
D) 不确定
回答： 
答案： C


(19) [ 单选 ] ID:16056
a=tf.constant(2)
b=tf.constant(5)
addOp=tf.greater(a,b) 程序语句执行结果 
A) addOp=“FALSE”
B) addOp=“TRUE”
C) addOp=“00”
D) addOp=“1”
回答： 
答案： A


(20) [ 单选 ] ID:16036
在tf中My_var_times_two = my_var.assign(2* my_var) 
A) 让my_var对应变量翻倍赋值给My_var_times_two
B) 没有赋值
C) 赋值不翻倍
D) my_var对应变量翻倍
回答： 
答案： D


(21) [ 多选 ] ID:16064
语句a = np.array([1,2,3,45,22,100])
s = tf.convert_to_tensor( a, name="sss")的正确断言是： 
A) a是np指定的张量
B) 可以实现对tf张量的任意填充
C) convert_to_tensor将a转换成tf张量
D) S是指向tf张量的结点
回答： 
答案： ABCD


(22) [ 多选 ] ID:16067
语句a=tf.Variable([1，2，3]）和b=tf.Variable(a）这条语句： 
A) 合法
B) 非法
C) 合法但a需要提前初始化
D) 合法但不够安全
回答： 
答案： ACD


(23) [ 多选 ] ID:16061
对于集合外一个点，到该集合的距离是 
A) 是该点到集合边界点的最短距离
B) 是该点到集合内所有点的最短距离
C) 是该点到集合内任意一点的距离
D) 是该点到集合内非边界点的某点的距离
回答： 
答案： AB


(24) [ 多选 ] ID:16069
单个神经元能解决什么问题 
A) 与
B) 或
C) 非
D) 异或
回答： 
答案： ABC


(25) [ 多选 ] ID:16062
语句My_var_times_two = my_var.assign(2* my_var) 
A) 让my_var对应变量翻倍
B) 有赋值
C) My_var_times_two是一个节点
D) 需要先对my_var初始化
回答： 
答案： ABCD


(26) [ 多选 ] ID:16065
在W.assign_add(10)的正确断言： 
A) W必须提前初始化
B) W对应值增加10
C) 执行后，W值为10
D) 通过sess.run()实现
回答： 
答案： ABD


(27) [ 多选 ] ID:16063
语句t = tf.ones_like(a)的几个意义是 
A) 将t节点内容用a替换
B) t节点对应张量维度和A相同
C) t对应张量值为1
D) a需要预先初始化
回答： 
答案： BCD


(28) [ 多选 ] ID:16057
深度学习网络的卷积部分的组成有 
A) 卷积层
B) RELU
C) POOLING层
D) pedding
回答： 
答案： ABC


(29) [ 多选 ] ID:16066
语句tf.variables_initializer语句可以 
A) 初始化一个变量
B) 初始化多个变量
C) 初始化全部变量
D) 初始化常量
回答： 
答案： ABC


(30) [ 多选 ] ID:16068
深度学习的兴起主要得益于三个方面的原因 
A) 新方法的出现，为神经网络深度的拓展解决了梯度弥散的问题；
B) 大量已标注数据的出现，为神经网络的训练做好了数据准备；
C) GPU（图形处理器）的使用，为卷积计算提供了高速解决方案
D) 深度学习等于人工智能
回答： 
答案： ABC


(31) [ 判断 ] ID:16077
tf语句X．Initializer的意义是对X常量初始化。 
回答： 
答案： 否


(32) [ 判断 ] ID:16076
对于形如[[[],[]]]的张量，它的维度向量是[1，2，0]。 
回答： 
答案： 是


(33) [ 判断 ] ID:16081
在tf语句中X.Value是将x中的内容取出。 
回答： 
答案： 否


(34) [ 判断 ] ID:16073
距离的大小程度，是一个标量。 
回答： 
答案： 是


(35) [ 判断 ] ID:16083
在机器学习框架方面，TensorFlow的真正独特之处在于，能够在5行或者10行代码中构建模型。然后应用这个模型，进行扩展做出产品。 
回答： 
答案： 是


(36) [ 判断 ] ID:16084
执行完语句tf.assign(start, new_value)后可以将变量start的值传递给新的变量new_value 
回答： 
答案： 否


(37) [ 判断 ] ID:16074
欧几里得距离，和曼哈顿距离的定义，互有矛盾。 
回答： 
答案： 否


(38) [ 判断 ] ID:16082
tf.Variable(initializer,name),参数initializer是初始化参数，name是可自定义的变量名称 
回答： 
答案： 是


(39) [ 判断 ] ID:16079
在tf可以定义多个Session对话。 
回答： 
答案： 是


(40) [ 判断 ] ID:16075
用卷积实现图像特征提取，就是借用共振原理。 
回答： 
答案： 否


(41) [ 判断 ] ID:16086
BP传播算法,主要由两个环节即(激励传播、权重更新)反复循环迭代，直到网络对输入的响应达到预定的目标/期望范围为止 
回答： 
答案： 是


(42) [ 判断 ] ID:16080
X.assign(100)是条立即数赋值语句。 
回答： 
答案： 是


(43) [ 判断 ] ID:16070
自然界任何物体都存在固定振动频率，当外界有相同频率振动，就能使该物体产生共振。 
回答： 
答案： 是


(44) [ 判断 ] ID:16078
tf中，tf.assign_add，也是赋值语句。 
回答： 
答案： 是


(45) [ 判断 ] ID:16087
在被卷积的2D图像上进行滑动，并在每个位置上与该像素点及其相领的像素点进行内积,这就是二维卷积的功能 
回答： 
答案： 是
